{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../implementation/')\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as sp\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from monadjemi_competing_models import CompetingModels\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the STL Crimes underlying data and user interaction data\n",
    "underlying_data = pd.read_csv('../data/stl_crimes/dots.csv')\n",
    "underlying_data.set_index('id', drop=True, inplace=True)\n",
    "output_file_path = '../output/stl/stl_map_results_competing_models.pkl'\n",
    "ks = [1, 5, 10, 20, 50, 100]\n",
    "interaction_data = pd.read_csv('../data/stl_crimes/stl_combined_interactions.csv')\n",
    "interaction_data['interaction_session'] = interaction_data.apply(lambda row: ast.literal_eval(row.interaction_session), axis=1)\n",
    "interaction_data['interaction_type_session'] = interaction_data.apply(lambda row: ast.literal_eval(row.interaction_type_session), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_index = 35\n",
    "\n",
    "competing_models = CompetingModels(underlying_data, [['x','y']], ['type'])\n",
    "ks = [1, 5, 10, 20, 50, 100]\n",
    "predicted = pd.DataFrame()\n",
    "for i in tqdm(range(len(interaction_data.iloc[interaction_index].interaction_session))):\n",
    "    interaction = interaction_data.iloc[interaction_index].interaction_session[i]\n",
    "    competing_models.update(interaction)\n",
    "    \n",
    "    if i < len(interaction_data.iloc[interaction_index].interaction_session) - 1:\n",
    "        probability_of_next_point = competing_models.predict()\n",
    "        next_point = interaction_data.iloc[interaction_index].interaction_session[i+1]\n",
    "        predicted_next_dict = {}\n",
    "        for k in ks:\n",
    "            predicted_next_dict[k] = (next_point in probability_of_next_point.nlargest(k).index.values)\n",
    "        predicted = predicted.append(predicted_next_dict, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competing_models.get_model_posterior().plot(title=f'{interaction_data.iloc[interaction_index].task}', alpha=0.5, lw=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competing_models.get_attribute_bias().plot(title=f'{interaction_data.iloc[interaction_index].task}', alpha=0.5, lw=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# success rate for predicting next click in the top-k\n",
    "ncp = predicted.sum()/len(predicted)\n",
    "ncp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This blocks runs competing models on all sessions and records the outputs\n",
    "# The results are saved to a file, so only need to run this block if you need new results\n",
    "\n",
    "stl_map_results = pd.DataFrame()\n",
    "for participant_index, row in interaction_data.iterrows():\n",
    "    print(f'Processing user {row.user} task {row.task}')\n",
    "    results = {'participant_id': row.user, 'task': row.task}\n",
    "    competing_models = CompetingModels(underlying_data, [['x','y']], ['type'])\n",
    "    predicted = pd.DataFrame()\n",
    "    rank_predicted = []\n",
    "\n",
    "    for i in tqdm(range(len(interaction_data.iloc[participant_index].interaction_session))):\n",
    "        interaction = interaction_data.iloc[participant_index].interaction_session[i]\n",
    "        competing_models.update(interaction)\n",
    "\n",
    "        if i < len(interaction_data.iloc[participant_index].interaction_session) - 1:\n",
    "            probability_of_next_point = competing_models.predict()\n",
    "            next_point = interaction_data.iloc[participant_index].interaction_session[i+1]\n",
    "            predicted_next_dict = {}\n",
    "            for k in ks:\n",
    "                predicted_next_dict[k] = (next_point in probability_of_next_point.nlargest(k).index.values)\n",
    "            predicted = predicted.append(predicted_next_dict, ignore_index=True)\n",
    "            sorted_prob = probability_of_next_point.sort_values(ascending=False)\n",
    "            rank, = np.where(sorted_prob.index.values == next_point)\n",
    "            rank_predicted.append(rank[0] + 1)\n",
    "            \n",
    "    ncp = predicted.sum()/len(predicted)\n",
    "    results['rank'] = rank_predicted\n",
    "\n",
    "    for col in ncp.index:\n",
    "        results[f'ncp-{col}'] = ncp[col]\n",
    "        \n",
    "    bias = competing_models.get_attribute_bias()\n",
    "    for col in bias.columns:\n",
    "        results[f'bias-{col}'] = bias[col].to_numpy()\n",
    "        \n",
    "    posterior = competing_models.get_model_posterior()\n",
    "    for col in posterior.columns:\n",
    "        results[f'posterior-{col}'] = posterior[col].to_numpy()\n",
    "    \n",
    "    stl_map_results = stl_map_results.append(results, ignore_index=True)\n",
    "    \n",
    "stl_map_results.to_pickle(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results if already saved\n",
    "\n",
    "stl_map_results = pd.read_pickle('../output/stl_map_results_competing_models.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, sharey=True, figsize=(4*6.4, 4.8))\n",
    "plt.rcParams.update({'axes.titlesize': 15, 'axes.labelsize': 15, 'xtick.labelsize':12, 'xtick.labelsize':12})\n",
    "for ax in axs:\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    ax.set(xlabel='Interactions Observed', ylabel='Avg. Bias')\n",
    "    ax.set_ylim((0, 1.05))\n",
    "#    ax.set_xlim((2, 15))\n",
    "\n",
    "bias_metric_per_task = {'geo-based': 'bias-x___y', 'type-based': 'bias-type', 'mixed': 'posterior-competing_model__x___y___type'}\n",
    "for ai, t in enumerate(['geo-based', 'type-based', 'mixed']):\n",
    "    bias_over_time = pd.DataFrame()\n",
    "    for i, row in stl_map_results[stl_map_results.task == t].iterrows():\n",
    "        temp_df = pd.DataFrame()\n",
    "        temp_df[row['participant_id']] = row[bias_metric_per_task[t]]\n",
    "        bias_over_time = pd.concat([bias_over_time, temp_df], axis=1, ignore_index=True)\n",
    "    sems = bias_over_time.std(axis=1) / np.sqrt(bias_over_time.count(axis=1))\n",
    "    mean = bias_over_time.mean(axis=1)\n",
    "    mean.plot(ax=axs[ai], title=f'Agrregate Bias Detection for {t} Task', label='Competing Models', color='#d95f02')\n",
    "    axs[ai].fill_between(list(range(len(mean))), mean-2*sems,mean+2*sems, color='#d95f02', alpha=0.3, zorder=100)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, sharey=True, figsize=(4*6.4, 4.8))\n",
    "plt.rcParams.update({'axes.titlesize': 15, 'axes.labelsize': 15, 'xtick.labelsize':12, 'xtick.labelsize':12})\n",
    "for ax in axs:\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    ax.set(xlabel='k', ylabel='Avg. Accuracy')\n",
    "    ax.set_ylim((0, 1.05))\n",
    "#    ax.set_xlim((2, 15))\n",
    "ks = [1, 5, 10, 20, 50, 100]\n",
    "for ai, t in enumerate(['geo-based', 'type-based', 'mixed']):\n",
    "    df_temp = stl_map_results[stl_map_results.task == t][[f'ncp-{k}' for k in ks]]\n",
    "    err = df_temp.std() / np.sqrt(len(df_temp))\n",
    "    df_temp.mean().plot.bar(yerr=err, ax=axs[ai], color='#d95f02', alpha=0.5, title=f'Aggregate Next Click Prediction for {t} Task')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stl_map_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
