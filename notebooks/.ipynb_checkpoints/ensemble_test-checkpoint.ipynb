{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae73990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../implementation')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as sp\n",
    "import time\n",
    "from util import flatten_list\n",
    "from ottley_hidden_markov_model import HMM\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e5fe0",
   "metadata": {},
   "source": [
    "# STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27532606",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../output/ensembles/'\n",
    "interaction_data = pd.read_csv('../data/stl_crimes/stl_combined_interactions.csv')\n",
    "interaction_data['interaction_session'] = interaction_data.apply(lambda row: ast.literal_eval(row.interaction_session), axis=1)\n",
    "output_file_path = '../output/stl/stl_map_results_ensemble.pkl'\n",
    "ks = [1, 5, 10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea1f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_results = pd.DataFrame()\n",
    "for participant_index, row in interaction_data.iterrows():\n",
    "    print(f'Processing user {row.user} task {row.task}')\n",
    "    results = {'participant_id': row.user, 'task': row.task}\n",
    "    predicted = pd.DataFrame()\n",
    "    rank_predicted = []\n",
    "    for i in tqdm(range(len(interaction_data.iloc[participant_index].interaction_session))):\n",
    "        if i < len(interaction_data.iloc[participant_index].interaction_session) - 1:\n",
    "            current_data_path = data_path + 'stl/' + str(participant_index) + '/'\n",
    "            user_data = np.load(current_data_path + str(i) + '.npy')\n",
    "            df = pd.DataFrame(user_data, columns = ['hmm','cm','af', 'bnb', 'knn'])\n",
    "            df['avg'] = df.mean(axis=1)\n",
    "            probability_of_next_point = df['avg']\n",
    "            next_point = interaction_data.iloc[participant_index].interaction_session[i+1]\n",
    "            predicted_next_dict = {}\n",
    "            for k in ks:\n",
    "                predicted_next_dict[k] = (next_point in probability_of_next_point.nlargest(k).index.values)\n",
    "            sorted_prob = probability_of_next_point.sort_values(ascending=False)\n",
    "            rank, = np.where(sorted_prob.index.values == next_point)\n",
    "            rank_predicted.append(rank[0])\n",
    "            predicted = predicted.append(predicted_next_dict, ignore_index=True)\n",
    "    ncp = predicted.sum()/len(predicted)\n",
    "    for col in ncp.index:\n",
    "        results[f'ncp-{col}'] = ncp[col]\n",
    "    results['rank'] = rank_predicted\n",
    "    ensemble_results = ensemble_results.append(results, ignore_index=True)\n",
    "    \n",
    "ensemble_results.to_pickle(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299078d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f49c16",
   "metadata": {},
   "source": [
    "# VAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3002a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../output/ensembles/'\n",
    "bookmarks_ui_data_path = '../data/vast_2011_challenge/bookmark_interactions_clean.pkl'\n",
    "interaction_data = pd.read_pickle(bookmarks_ui_data_path)\n",
    "interaction_data = interaction_data[interaction_data['experimental_group'] == 'control']\n",
    "interaction_data = interaction_data.reset_index(drop=True)\n",
    "# interaction_data['interaction_session'] = interaction_data.apply(lambda row: ast.literal_eval(row.interaction_session), axis=1)\n",
    "output_file_path = '../output/vast/vast_11_ensemble.pkl'\n",
    "ks = [1, 5, 10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0bb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_results = pd.DataFrame()\n",
    "for participant_index, row in interaction_data.iterrows():\n",
    "    print(f'Processing user {row.user} task {row.experimental_group}')\n",
    "    results = {'participant_id': row.user, 'task': row.experimental_group}\n",
    "    predicted = pd.DataFrame()\n",
    "    rank_predicted = []\n",
    "    for i in tqdm(range(len(interaction_data.iloc[participant_index].interaction_session))):\n",
    "        if i < len(interaction_data.iloc[participant_index].interaction_session) - 1:\n",
    "            current_data_path = data_path + 'vast/' + str(participant_index) + '/'\n",
    "            user_data = np.load(current_data_path + str(i) + '.npy')\n",
    "            df = pd.DataFrame(user_data, columns = ['hmm','cm','af', 'bnb', 'knn'])\n",
    "            df['avg'] = df.mean(axis=1)\n",
    "            probability_of_next_point = df['avg']\n",
    "            next_point = interaction_data.iloc[participant_index].interaction_session[i+1]\n",
    "            predicted_next_dict = {}\n",
    "            for k in ks:\n",
    "                predicted_next_dict[k] = (next_point in probability_of_next_point.nlargest(k).index.values)\n",
    "            sorted_prob = probability_of_next_point.sort_values(ascending=False)\n",
    "            rank, = np.where(sorted_prob.index.values == next_point)\n",
    "            rank_predicted.append(rank[0])\n",
    "            predicted = predicted.append(predicted_next_dict, ignore_index=True)\n",
    "    ncp = predicted.sum()/len(predicted)\n",
    "    for col in ncp.index:\n",
    "        results[f'ncp-{col}'] = ncp[col]\n",
    "    results['rank'] = rank_predicted\n",
    "    ensemble_results = ensemble_results.append(results, ignore_index=True)\n",
    "    \n",
    "ensemble_results.to_pickle(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2364272",
   "metadata": {},
   "source": [
    "# Boardrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b486acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../output/ensembles/'\n",
    "ui_data_path = '../data/boardrooms/boardrooms_combined_interactions.csv'\n",
    "interaction_data = pd.read_csv(ui_data_path)\n",
    "interaction_data['interaction_session'] = interaction_data.apply(lambda row: ast.literal_eval(row.interaction_session), axis=1)\n",
    "output_file_path = '../output/boardrooms/boardrooms_ensemble.pkl'\n",
    "ks = [1, 5, 10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_results = pd.DataFrame()\n",
    "for participant_index, row in interaction_data.iterrows():\n",
    "    print(f'Processing user {row.user} task {row.task}')\n",
    "    results = {'participant_id': row.user, 'task': row.task}\n",
    "    predicted = pd.DataFrame()\n",
    "    rank_predicted = []\n",
    "    for i in tqdm(range(len(interaction_data.iloc[participant_index].interaction_session))):\n",
    "        if i < len(interaction_data.iloc[participant_index].interaction_session) - 1:\n",
    "            current_data_path = data_path + 'boardrooms/' + str(participant_index) + '/'\n",
    "            user_data = np.load(current_data_path + str(i) + '.npy')\n",
    "            df = pd.DataFrame(user_data, columns = ['hmm','cm','af', 'bnb', 'knn'])\n",
    "            df['avg'] = df.mean(axis=1)\n",
    "            probability_of_next_point = df['avg']\n",
    "            next_point = interaction_data.iloc[participant_index].interaction_session[i+1]\n",
    "            predicted_next_dict = {}\n",
    "            for k in ks:\n",
    "                predicted_next_dict[k] = (next_point in probability_of_next_point.nlargest(k).index.values)\n",
    "            sorted_prob = probability_of_next_point.sort_values(ascending=False)\n",
    "            rank, = np.where(sorted_prob.index.values == next_point)\n",
    "            rank_predicted.append(rank[0])\n",
    "            predicted = predicted.append(predicted_next_dict, ignore_index=True)\n",
    "    ncp = predicted.sum()/len(predicted)\n",
    "    for col in ncp.index:\n",
    "        results[f'ncp-{col}'] = ncp[col]\n",
    "    results['rank'] = rank_predicted\n",
    "    ensemble_results = ensemble_results.append(results, ignore_index=True)\n",
    "    \n",
    "ensemble_results.to_pickle(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10000c04",
   "metadata": {},
   "source": [
    "# Political Committee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a369db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../output/ensembles/'\n",
    "ui_data_path = '../data/political/final/wall_political_interactions.csv'\n",
    "interaction_data = pd.read_csv(ui_data_path)\n",
    "interaction_data['interaction_session'] = interaction_data.apply(lambda row: ast.literal_eval(row.interaction_session), axis=1)\n",
    "output_file_path = '../output/political/political_ensemble.pkl'\n",
    "ks = [1, 5, 10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_results = pd.DataFrame()\n",
    "for participant_index, row in interaction_data.iterrows():\n",
    "    print(f'Processing user {row.user}')\n",
    "    results = {'participant_id': row.user}\n",
    "    predicted = pd.DataFrame()\n",
    "    rank_predicted = []\n",
    "    for i in tqdm(range(len(interaction_data.iloc[participant_index].interaction_session))):\n",
    "        if i < len(interaction_data.iloc[participant_index].interaction_session) - 1:\n",
    "            current_data_path = data_path + 'political/' + str(participant_index) + '/'\n",
    "            user_data = np.load(current_data_path + str(i) + '.npy')\n",
    "            df = pd.DataFrame(user_data, columns = ['hmm','cm','af', 'bnb', 'knn'])\n",
    "            df['avg'] = df.mean(axis=1)\n",
    "            probability_of_next_point = df['avg']\n",
    "            next_point = interaction_data.iloc[participant_index].interaction_session[i+1]\n",
    "            predicted_next_dict = {}\n",
    "            for k in ks:\n",
    "                predicted_next_dict[k] = (next_point in probability_of_next_point.nlargest(k).index.values)\n",
    "            sorted_prob = probability_of_next_point.sort_values(ascending=False)\n",
    "            rank, = np.where(sorted_prob.index.values == next_point)\n",
    "            rank_predicted.append(rank[0])\n",
    "            predicted = predicted.append(predicted_next_dict, ignore_index=True)\n",
    "    ncp = predicted.sum()/len(predicted)\n",
    "    for col in ncp.index:\n",
    "        results[f'ncp-{col}'] = ncp[col]\n",
    "    results['rank'] = rank_predicted\n",
    "    ensemble_results = ensemble_results.append(results, ignore_index=True)\n",
    "    \n",
    "ensemble_results.to_pickle(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d3338",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958c6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
